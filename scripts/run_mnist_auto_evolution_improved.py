#!/usr/bin/env python3
"""
MNIST è‡ªåŠ¨æ¼”åŒ–å®éªŒè„šæœ¬ï¼ˆæ”¹è¿›ç‰ˆï¼‰
åº”ç”¨æ­£åˆ™åŒ–å’Œæ”¹è¿›æªæ–½æ¥è§£å†³è¿‡æ‹Ÿåˆé—®é¢˜
"""
import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

import json
import argparse
from typing import Dict, Optional

import torch
from torch.optim import Adam
from tqdm import tqdm

from aonn.models.mnist_world_model import MNISTWorldModel, MNISTWorldInterface
from aonn.models.aonn_brain_v3 import AONNBrainV3
from aonn.core.active_inference_loop import ActiveInferenceLoop
from aonn.aspects.classification_aspect import ClassificationAspect


def evaluate_on_dataset(
    brain,
    world_interface,
    classification_aspect,
    num_samples: int,
    config: Dict,
    device: torch.device,
    use_inference: bool = True,
):
    """åœ¨æ•°æ®é›†ä¸Šè¯„ä¼°å‡†ç¡®ç‡"""
    correct = 0
    
    with torch.no_grad():
        obs = world_interface.reset()
        
        for i in range(num_samples):
            # è®¾ç½®è§‚å¯Ÿ
            for sense, value in obs.items():
                if sense in brain.objects:
                    brain.objects[sense].set_state(value)
            
            # è·å–ç›®æ ‡ï¼ˆç”¨äºæ¨ç†ï¼‰
            target = world_interface.get_target()
            brain.objects["target"].set_state(target)
            
            # ä¸»åŠ¨æ¨ç†ï¼ˆå¯é€‰ï¼Œç”¨äºè¯„ä¼°ï¼‰
            if use_inference and len(brain.aspects) > 0:
                try:
                    loop = ActiveInferenceLoop(
                        brain.objects,
                        brain.aspects,
                        infer_lr=config.get("infer_lr", 0.01),
                        max_grad_norm=config.get("max_grad_norm", 100.0),
                        device=device,
                    )
                    # è¯„ä¼°æ—¶ä½¿ç”¨æ›´å°‘çš„æ¨ç†è¿­ä»£
                    loop.infer_states(
                        target_objects=("internal",),
                        num_iters=config.get("eval_infer_iters", 1),  # è¯„ä¼°æ—¶åªç”¨ 1 æ¬¡è¿­ä»£
                        sanitize_callback=brain.sanitize_states
                    )
                except Exception:
                    pass
            
            # é¢„æµ‹
            logits = classification_aspect.predict(brain.objects)
            pred_label = logits.argmax().item()
            true_label = world_interface.world_model.get_label()
            
            if pred_label == true_label:
                correct += 1
            
            # ç§»åŠ¨åˆ°ä¸‹ä¸€ä¸ªæ ·æœ¬ï¼ˆéšæœºæˆ–é¡ºåºï¼‰
            action = torch.softmax(logits, dim=-1)
            obs, _ = world_interface.step(action)
    
    accuracy = correct / num_samples
    return accuracy


def run_experiment(
    num_steps: int,
    config: Dict,
    device: torch.device,
    *,
    verbose: bool = False,
    output: str = "data/mnist_auto_evolution_improved.json",
    save_interval: int = 1000,
):
    """è¿è¡Œ MNIST è‡ªåŠ¨æ¼”åŒ–å®éªŒï¼ˆæ”¹è¿›ç‰ˆï¼‰"""
    
    # åˆ›å»ºè®­ç»ƒå’ŒéªŒè¯ä¸–ç•Œæ¨¡å‹
    train_world = MNISTWorldModel(
        state_dim=config.get("state_dim", 128),
        action_dim=config.get("act_dim", 10),
        obs_dim=config.get("obs_dim", 784),
        device=device,
        train=True,
    )
    train_interface = MNISTWorldInterface(train_world)
    
    val_world = MNISTWorldModel(
        state_dim=config.get("state_dim", 128),
        action_dim=config.get("act_dim", 10),
        obs_dim=config.get("obs_dim", 784),
        device=device,
        train=False,  # ä½¿ç”¨æµ‹è¯•é›†
    )
    val_interface = MNISTWorldInterface(val_world)
    
    # åˆ›å»º AONN Brainï¼ˆæœ€å°åˆå§‹æ¶æ„ï¼Œä¸åŒ…å« vision_pipelineï¼‰
    brain = AONNBrainV3(config=config, device=device, enable_evolution=True)
    
    # åˆ›å»º target Object
    brain.create_object("target", dim=10)
    
    print("åˆå§‹åŒ– AONN Brainï¼ˆè‡ªåŠ¨æ¼”åŒ–æ¨¡å¼ - æ”¹è¿›ç‰ˆï¼‰...")
    print("  âœ“ åˆå§‹ç½‘ç»œï¼šæœ€å°æ¶æ„ï¼ˆæ—  vision_pipelineï¼‰")
    print("  âœ“ ç­‰å¾…è‡ªåŠ¨æ¼”åŒ–åˆ›å»º vision_pipeline...")
    print()
    
    # åˆ›å»ºåˆ†ç±»å™¨ï¼ˆè¿™ä¸ªå¯ä»¥é¢„å…ˆåˆ›å»ºï¼Œå› ä¸ºåˆ†ç±»å™¨ä¸æ˜¯è‡ªåŠ¨æ¼”åŒ–çš„ç›®æ ‡ï¼‰
    classification_aspect = brain.create_unified_aspect(
        aspect_type="classification",
        src_names=["internal"],
        dst_names=["target"],
        name="mnist_classifier",
        state_dim=config.get("state_dim", 128),
        num_classes=10,
        hidden_dim=config.get("state_dim", 128),
        loss_weight=config.get("classification_loss_weight", 1.0),
    )
    print(f"  âœ“ åˆ›å»º mnist_classifier (state_dim={config.get('state_dim', 128)}, num_classes=10)")
    print()
    
    # åˆ›å»º Adam ä¼˜åŒ–å™¨ï¼ˆåˆå§‹åªåŒ…å«åˆ†ç±»å™¨ï¼Œvision_pipeline ä¼šåœ¨æ¼”åŒ–åæ·»åŠ ï¼‰
    # æ”¹è¿›ï¼šæ·»åŠ æƒé‡è¡°å‡
    aspect_params = list(classification_aspect.parameters())
    weight_decay = config.get("weight_decay", 1e-4)
    aspect_optimizer = Adam(
        aspect_params,
        lr=config.get("learning_rate", 0.0001),  # æ”¹è¿›ï¼šé™ä½å­¦ä¹ ç‡
        weight_decay=weight_decay,  # æ”¹è¿›ï¼šæ·»åŠ æƒé‡è¡°å‡
        betas=(0.9, 0.999),
        eps=1e-8,
    )
    print(f"  âœ“ åˆå§‹åŒ– Adam ä¼˜åŒ–å™¨: lr={config.get('learning_rate', 0.0001)}, weight_decay={weight_decay}")
    print()
    
    snapshots = []
    accuracy_history = []
    free_energy_history = []
    train_acc_history = []  # æ”¹è¿›ï¼šè®°å½•è®­ç»ƒé›†å‡†ç¡®ç‡
    val_acc_history = []    # æ”¹è¿›ï¼šè®°å½•éªŒè¯é›†å‡†ç¡®ç‡
    evolution_events = []  # è®°å½•æ¼”åŒ–äº‹ä»¶
    
    # åˆå§‹åŒ–è§‚å¯Ÿ
    obs = train_interface.reset()
    action = None
    prev_obs = None
    
    # æ£€æŸ¥ vision_pipeline æ˜¯å¦å·²åˆ›å»º
    vision_pipeline_created = False
    
    # æ”¹è¿›ï¼šæ—©åœæœºåˆ¶
    best_val_acc = 0.0
    patience = 0
    max_patience = config.get("max_patience", 10)
    
    progress = tqdm(range(num_steps), desc=f"MNIST Auto Evolution Improved {num_steps}")
    
    try:
        for step in progress:
            # æ”¹è¿›ï¼šä½¿ç”¨éšæœºé‡‡æ ·è€Œä¸æ˜¯é¡ºåºéå†
            if config.get("use_random_sampling", True):
                # éšæœºé€‰æ‹©æ ·æœ¬
                obs = train_interface.reset()
            else:
                # é¡ºåºéå†ï¼ˆåŸå§‹æ–¹å¼ï¼‰
                if step > 0:
                    obs, reward = train_interface.step(action)
                else:
                    obs = train_interface.reset()
            
            # è®¾ç½®è§‚å¯Ÿ
            for sense, value in obs.items():
                if sense in brain.objects:
                    brain.objects[sense].set_state(value)
            
            # è·å–ç›®æ ‡æ ‡ç­¾
            target = train_interface.get_target()
            brain.objects["target"].set_state(target)
            
            # 2. ç½‘ç»œæ¼”åŒ–ï¼ˆè¿™é‡Œä¼šè‡ªåŠ¨åˆ›å»º vision_pipelineï¼‰
            num_aspects_before = len(brain.aspects)
            brain.evolve_network(obs)
            num_aspects_after = len(brain.aspects)
            
            # æ£€æŸ¥æ˜¯å¦åˆ›å»ºäº† vision_pipeline
            if not vision_pipeline_created:
                vision_pipeline = None
                for asp in brain.aspects:
                    if (hasattr(asp, 'name') and 
                        ('vision' in asp.name.lower() and 'pipeline' in asp.name.lower())):
                        vision_pipeline = asp
                        vision_pipeline_created = True
                        evolution_events.append({
                            "step": step + 1,
                            "event": "vision_pipeline_created",
                            "name": asp.name,
                            "free_energy": brain.compute_free_energy().item(),
                        })
                        print(f"\nğŸ‰ [Step {step+1}] è‡ªåŠ¨æ¼”åŒ–åˆ›å»ºäº† vision_pipeline: {asp.name}")
                        # æ›´æ–°ä¼˜åŒ–å™¨ï¼Œæ·»åŠ  vision_pipeline çš„å‚æ•°
                        aspect_params = list(asp.parameters()) + list(classification_aspect.parameters())
                        aspect_optimizer = Adam(
                            aspect_params,
                            lr=config.get("learning_rate", 0.0001),
                            weight_decay=weight_decay,
                            betas=(0.9, 0.999),
                            eps=1e-8,
                        )
                        print(f"  âœ“ æ›´æ–°ä¼˜åŒ–å™¨ï¼Œæ·»åŠ  vision_pipeline å‚æ•°")
                        break
            
            # å¦‚æœ vision_pipeline å·²åˆ›å»ºï¼Œè·å–å®ƒ
            if vision_pipeline_created and vision_pipeline is None:
                for asp in brain.aspects:
                    if (hasattr(asp, 'name') and 
                        ('vision' in asp.name.lower() and 'pipeline' in asp.name.lower())):
                        vision_pipeline = asp
                        break
            
            # 3. ä¸»åŠ¨æ¨ç†ï¼ˆçŠ¶æ€æ¨ç†ï¼‰
            if len(brain.aspects) > 0:
                try:
                    # ç¡®ä¿çŠ¶æ€æ˜¯ detached çš„
                    for obj_name, obj in brain.objects.items():
                        state = obj.state
                        if state.requires_grad and state.is_leaf and state.grad is not None:
                            obj.set_state(state.detach())
                        elif not state.is_leaf:
                            obj.set_state(state.detach())
                    
                    loop = ActiveInferenceLoop(
                        brain.objects,
                        brain.aspects,
                        infer_lr=config.get("infer_lr", 0.01),
                        max_grad_norm=config.get("max_grad_norm", 100.0),
                        device=device,
                    )
                    num_iters = config.get("num_infer_iters", 5)
                    loop.infer_states(
                        target_objects=("internal",),
                        num_iters=num_iters,
                        sanitize_callback=brain.sanitize_states
                    )
                    brain.sanitize_states()
                except Exception as e:
                    if verbose:
                        print(f"Step {step}: Inference error: {e}")
                    pass
            
            # 4. å‚æ•°å­¦ä¹ ï¼ˆä½¿ç”¨ Adam ä¼˜åŒ–å™¨ï¼‰
            if step > 0 and vision_pipeline_created:  # åªæœ‰ vision_pipeline åˆ›å»ºåæ‰å­¦ä¹ 
                try:
                    aspect_optimizer.zero_grad()
                    F = brain.compute_free_energy()
                    
                    if torch.isfinite(F) and F.requires_grad:
                        F.backward()
                        
                        # æ¢¯åº¦è£å‰ª
                        max_grad_norm = config.get("max_grad_norm", None)
                        if max_grad_norm is not None:
                            torch.nn.utils.clip_grad_norm_(aspect_params, max_grad_norm)
                        
                        aspect_optimizer.step()
                        brain.sanitize_states()
                except Exception as e:
                    if verbose:
                        print(f"Step {step}: Learning error: {e}")
                    pass
            
            # 5. ç”ŸæˆåŠ¨ä½œï¼ˆåˆ†ç±»é¢„æµ‹ï¼‰
            with torch.no_grad():
                logits = classification_aspect.predict(brain.objects)
                action = torch.softmax(logits, dim=-1)
                
                # è¯„ä¼°å‡†ç¡®ç‡ï¼ˆå½“å‰æ ·æœ¬ï¼‰
                pred_label = logits.argmax().item()
                true_label = train_interface.world_model.get_label()
                correct = (pred_label == true_label)
                accuracy_history.append(1.0 if correct else 0.0)
            
            # 6. è®°å½•è‡ªç”±èƒ½
            with torch.no_grad():
                F = brain.compute_free_energy()
                free_energy_history.append(F.item())
            
            # æ”¹è¿›ï¼šå®šæœŸè¯„ä¼°è®­ç»ƒé›†å’ŒéªŒè¯é›†å‡†ç¡®ç‡
            eval_interval = config.get("eval_interval", 1000)
            if (step + 1) % eval_interval == 0 or step == num_steps - 1:
                print(f"\n[Step {step+1}] è¯„ä¼°å‡†ç¡®ç‡...")
                
                # è¯„ä¼°è®­ç»ƒé›†å‡†ç¡®ç‡ï¼ˆä½¿ç”¨ 1000 ä¸ªæ ·æœ¬ï¼‰
                train_acc = evaluate_on_dataset(
                    brain=brain,
                    world_interface=train_interface,
                    classification_aspect=classification_aspect,
                    num_samples=min(1000, len(train_world.dataset)),
                    config=config,
                    device=device,
                    use_inference=True,
                )
                train_acc_history.append({"step": step + 1, "accuracy": train_acc})
                
                # è¯„ä¼°éªŒè¯é›†å‡†ç¡®ç‡ï¼ˆä½¿ç”¨å…¨éƒ¨æµ‹è¯•é›†æˆ– 10000 ä¸ªæ ·æœ¬ï¼‰
                val_num_samples = min(config.get("val_num_samples", 10000), len(val_world.dataset))
                val_acc = evaluate_on_dataset(
                    brain=brain,
                    world_interface=val_interface,
                    classification_aspect=classification_aspect,
                    num_samples=val_num_samples,
                    config=config,
                    device=device,
                    use_inference=True,
                )
                val_acc_history.append({"step": step + 1, "accuracy": val_acc})
                
                print(f"  è®­ç»ƒé›†å‡†ç¡®ç‡: {train_acc*100:.2f}%")
                print(f"  éªŒè¯é›†å‡†ç¡®ç‡: {val_acc*100:.2f}%")
                
                # æ—©åœæœºåˆ¶
                if val_acc > best_val_acc:
                    best_val_acc = val_acc
                    patience = 0
                else:
                    patience += 1
                    if patience >= max_patience:
                        print(f"\nâš ï¸  éªŒè¯å‡†ç¡®ç‡è¿ç»­ {max_patience} æ¬¡æœªæå‡ï¼Œæ—©åœ")
                        break
            
            # 7. ä¿å­˜å¿«ç…§
            if (step + 1) % save_interval == 0 or step == num_steps - 1:
                structure = brain.get_network_structure()
                # æ”¹è¿›ï¼šä½¿ç”¨æœ€è¿‘è¯„ä¼°çš„è®­ç»ƒé›†å‡†ç¡®ç‡ï¼Œè€Œä¸æ˜¯æœ€è¿‘ 100 æ­¥
                recent_train_acc = train_acc_history[-1]["accuracy"] if train_acc_history else 0.0
                recent_val_acc = val_acc_history[-1]["accuracy"] if val_acc_history else 0.0
                avg_F = sum(free_energy_history[-100:]) / min(100, len(free_energy_history))
                
                snapshot = {
                    "step": step + 1,
                    "free_energy": avg_F,
                    "train_accuracy": recent_train_acc,
                    "val_accuracy": recent_val_acc,
                    "structure": structure,
                    "vision_pipeline_created": vision_pipeline_created,
                }
                snapshots.append(snapshot)
            
            # 8. æ›´æ–°è¿›åº¦æ¡
            avg_F = sum(free_energy_history[-100:]) / min(100, len(free_energy_history))
            structure = brain.get_network_structure()
            
            # æ”¹è¿›ï¼šæ˜¾ç¤ºæœ€è¿‘è¯„ä¼°çš„å‡†ç¡®ç‡
            recent_train_acc = train_acc_history[-1]["accuracy"] if train_acc_history else 0.0
            recent_val_acc = val_acc_history[-1]["accuracy"] if val_acc_history else 0.0
            
            vision_status = "âœ“" if vision_pipeline_created else "âœ—"
            progress.set_postfix(
                F=f"{avg_F:.3f}",
                Train=f"{recent_train_acc*100:.1f}%",
                Val=f"{recent_val_acc*100:.1f}%",
                Asp=structure.get('num_aspects', 0),
                Pipe=structure.get('num_pipelines', 0),
                Vision=vision_status,
            )
            
            if verbose and (step + 1) % 50 == 0:
                print(f"[Step {step+1}] F={avg_F:.4f}, "
                      f"Train={recent_train_acc*100:.2f}%, Val={recent_val_acc*100:.2f}%, "
                      f"Aspects={structure.get('num_aspects', 0)}, "
                      f"Vision Pipeline={'Created' if vision_pipeline_created else 'Not Created'}")
            
            prev_obs = {sense: value.clone() for sense, value in obs.items()}
    
    except KeyboardInterrupt:
        print("\n\nâš ï¸  å®éªŒè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\n\nâŒ å®éªŒå‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
    
    # æœ€ç»ˆéªŒè¯ï¼ˆä½¿ç”¨å…¨éƒ¨æµ‹è¯•é›†ï¼‰
    print("\nå¼€å§‹æœ€ç»ˆéªŒè¯ï¼ˆä½¿ç”¨å…¨éƒ¨æµ‹è¯•é›†ï¼‰...")
    final_val_acc = evaluate_on_dataset(
        brain=brain,
        world_interface=val_interface,
        classification_aspect=classification_aspect,
        num_samples=len(val_world.dataset),  # ä½¿ç”¨å…¨éƒ¨æµ‹è¯•é›†
        config=config,
        device=device,
        use_inference=True,
    )
    
    # æœ€ç»ˆè®­ç»ƒé›†è¯„ä¼°ï¼ˆä½¿ç”¨ 5000 ä¸ªæ ·æœ¬ï¼‰
    print("å¼€å§‹æœ€ç»ˆè®­ç»ƒé›†è¯„ä¼°...")
    final_train_acc = evaluate_on_dataset(
        brain=brain,
        world_interface=train_interface,
        classification_aspect=classification_aspect,
        num_samples=min(5000, len(train_world.dataset)),
        config=config,
        device=device,
        use_inference=True,
    )
    
    # æœ€ç»ˆç»“æœ
    final_snapshot = brain.observe_self_model()
    final_F = free_energy_history[-1] if free_energy_history else 0.0
    
    result = {
        "num_steps": num_steps,
        "vision_pipeline_created": vision_pipeline_created,
        "evolution_events": evolution_events,
        "final_free_energy": final_F,
        "final_train_accuracy": final_train_acc,
        "final_val_accuracy": final_val_acc,
        "best_val_accuracy": best_val_acc,
        "final_structure": final_snapshot.get("structure", {}),
        "snapshots": snapshots,
        "train_acc_history": train_acc_history,
        "val_acc_history": val_acc_history,
        "accuracy_history": accuracy_history[-1000:],  # ä¿ç•™æœ€è¿‘ 1000 æ­¥
        "free_energy_history": free_energy_history[-1000:],
        "evolution_summary": brain.evolution.get_evolution_summary() if brain.evolution else {},
    }
    
    return result


def main():
    parser = argparse.ArgumentParser(description="MNIST è‡ªåŠ¨æ¼”åŒ–å®éªŒï¼ˆæ”¹è¿›ç‰ˆï¼‰")
    parser.add_argument("--steps", type=int, default=60000, help="è®­ç»ƒæ­¥æ•°")
    parser.add_argument("--state-dim", type=int, default=128, help="çŠ¶æ€ç»´åº¦")
    parser.add_argument("--verbose", action="store_true", help="è¯¦ç»†è¾“å‡º")
    parser.add_argument("--output", type=str, default="data/mnist_auto_evolution_improved.json", help="è¾“å‡ºæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--device", type=str, default="cpu", help="è®¾å¤‡")
    parser.add_argument("--save-interval", type=int, default=1000, help="å¿«ç…§ä¿å­˜é—´éš”")
    
    args = parser.parse_args()
    
    device = torch.device(args.device)
    
    # é…ç½®ï¼ˆå¯ç”¨è‡ªåŠ¨æ¼”åŒ–åˆ›å»º vision_pipeline + æ”¹è¿›æªæ–½ï¼‰
    config = {
        "obs_dim": 784,
        "state_dim": args.state_dim,
        "act_dim": 10,
        "sense_dims": {"vision": 784},
        "enable_world_model_learning": False,
        "evolution": {
            "free_energy_threshold": 2.0,  # è‡ªç”±èƒ½é˜ˆå€¼ï¼Œè¶…è¿‡æ­¤å€¼ä¼šè§¦å‘è‡ªåŠ¨åˆ›å»º
            "prune_threshold": 0.01,
            "max_objects": 20,
            "max_aspects": 500,
            "error_ema_alpha": 0.5,
            "batch_growth": {
                "base": 0,
                "max_per_step": 0,
                "max_total": 0,
                "min_per_sense": 0,
            },
            "pipeline_growth": {
                "enable": False,  # ç¦ç”¨è‡ªåŠ¨åˆ›å»º internal->internal pipeline
            },
        },
        # å…³é”®é…ç½®ï¼šå¯ç”¨è‡ªåŠ¨åˆ›å»º vision_pipeline
        "pipeline_growth": {
            "use_pipeline_for_encoder": True,  # ä½¿ç”¨ Pipeline è€Œä¸æ˜¯ç®€å•çš„ Encoder
            "initial_width": 32,  # Pipeline å®½åº¦
            "initial_depth": 4,   # Pipeline æ·±åº¦
        },
        # æ”¹è¿›æªæ–½
        "infer_lr": 0.01,
        "learning_rate": 0.0001,  # æ”¹è¿›ï¼šé™ä½å­¦ä¹ ç‡ï¼ˆä» 0.001 é™åˆ° 0.0001ï¼‰
        "weight_decay": 1e-4,     # æ”¹è¿›ï¼šæ·»åŠ æƒé‡è¡°å‡
        "classification_loss_weight": 1.0,
        "num_infer_iters": 5,      # è®­ç»ƒæ—¶æ¨ç†è¿­ä»£æ¬¡æ•°
        "eval_infer_iters": 1,     # æ”¹è¿›ï¼šè¯„ä¼°æ—¶ä½¿ç”¨æ›´å°‘çš„æ¨ç†è¿­ä»£
        "max_grad_norm": 100.0,
        "state_clip_value": 5.0,
        "use_random_sampling": True,  # æ”¹è¿›ï¼šä½¿ç”¨éšæœºé‡‡æ ·
        "eval_interval": 1000,        # æ”¹è¿›ï¼šæ¯ 1000 æ­¥è¯„ä¼°ä¸€æ¬¡
        "val_num_samples": 10000,     # æ”¹è¿›ï¼šéªŒè¯æ—¶ä½¿ç”¨ 10000 ä¸ªæ ·æœ¬
        "max_patience": 10,           # æ”¹è¿›ï¼šæ—©åœæœºåˆ¶ï¼Œè¿ç»­ 10 æ¬¡æœªæå‡åˆ™åœæ­¢
    }
    
    print("=" * 80)
    print("MNIST è‡ªåŠ¨æ¼”åŒ–å®éªŒï¼ˆæ”¹è¿›ç‰ˆï¼‰")
    print("=" * 80)
    print(f"è®­ç»ƒæ­¥æ•°: {args.steps}")
    print(f"çŠ¶æ€ç»´åº¦: {config['state_dim']}")
    print(f"è§‚å¯Ÿç»´åº¦: {config['obs_dim']}")
    print(f"åŠ¨ä½œç»´åº¦: {config['act_dim']}")
    print(f"è‡ªç”±èƒ½é˜ˆå€¼: {config['evolution']['free_energy_threshold']}")
    print(f"è‡ªåŠ¨åˆ›å»º vision_pipeline: å¯ç”¨")
    print(f"Pipeline é…ç½®: depth={config['pipeline_growth']['initial_depth']}, "
          f"width={config['pipeline_growth']['initial_width']}")
    print()
    print("æ”¹è¿›æªæ–½ï¼š")
    print(f"  âœ“ é™ä½å­¦ä¹ ç‡: {config['learning_rate']} (åŸ 0.001)")
    print(f"  âœ“ æ·»åŠ æƒé‡è¡°å‡: {config['weight_decay']}")
    print(f"  âœ“ ä½¿ç”¨éšæœºé‡‡æ ·: {config['use_random_sampling']}")
    print(f"  âœ“ è¯„ä¼°é—´éš”: æ¯ {config['eval_interval']} æ­¥")
    print(f"  âœ“ éªŒè¯æ ·æœ¬æ•°: {config['val_num_samples']} (åŸ 1000)")
    print(f"  âœ“ è¯„ä¼°æ¨ç†è¿­ä»£: {config['eval_infer_iters']} (åŸ 3)")
    print(f"  âœ“ æ—©åœæœºåˆ¶: è¿ç»­ {config['max_patience']} æ¬¡æœªæå‡åˆ™åœæ­¢")
    print("=" * 80)
    print()
    
    result = run_experiment(
        num_steps=args.steps,
        config=config,
        device=device,
        verbose=args.verbose,
        output=args.output,
        save_interval=args.save_interval,
    )
    
    # ä¿å­˜ç»“æœ
    output_path = Path(__file__).parent.parent / args.output
    output_path.parent.mkdir(parents=True, exist_ok=True)
    with open(output_path, "w") as f:
        json.dump(result, f, indent=2, default=str)
    
    print()
    print("=" * 80)
    print("å®éªŒå®Œæˆï¼")
    print("=" * 80)
    print(f"ç»“æœä¿å­˜åˆ°: {output_path}")
    print(f"vision_pipeline æ˜¯å¦è‡ªåŠ¨åˆ›å»º: {'æ˜¯' if result['vision_pipeline_created'] else 'å¦'}")
    if result['evolution_events']:
        for event in result['evolution_events']:
            print(f"  æ­¥éª¤ {event['step']}: {event['event']} ({event['name']}), "
                  f"è‡ªç”±èƒ½={event['free_energy']:.4f}")
    print(f"æœ€ç»ˆè‡ªç”±èƒ½: {result['final_free_energy']:.4f}")
    print(f"æœ€ç»ˆè®­ç»ƒå‡†ç¡®ç‡: {result['final_train_accuracy']*100:.2f}%")
    print(f"æœ€ç»ˆéªŒè¯å‡†ç¡®ç‡: {result['final_val_accuracy']*100:.2f}%")
    print(f"æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {result['best_val_accuracy']*100:.2f}%")
    print(f"å‡†ç¡®ç‡å·®å¼‚: {(result['final_train_accuracy'] - result['final_val_accuracy'])*100:.2f}%")
    print(f"æœ€ç»ˆç»“æ„: {result['final_structure'].get('num_objects', 0)} Objects, "
          f"{result['final_structure'].get('num_aspects', 0)} Aspects, "
          f"{result['final_structure'].get('num_pipelines', 0)} Pipelines")
    print("=" * 80)


if __name__ == "__main__":
    main()

