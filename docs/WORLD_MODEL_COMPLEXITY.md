# 世界模型复杂度分析

本文档分析不同复杂度级别的世界模型，以及 LLMAspect 如何降低 AONN 的有效复杂度。

## 一、线虫世界模型复杂度（当前实现）

基于 `src/aonn/models/lineworm_world_model.py` 的实现：

### 1. 状态空间复杂度

- **隐藏状态维度**: 256 维
- **物理状态**: 4 维（位置 2D + 朝向 1D + 能量 1D）
- **总状态维度**: ~260 维
- **状态空间大小**: 连续空间，无离散化

### 2. 动作空间复杂度

- **动作维度**: 32 维（实际使用前 2 维：推进 + 转向）
- **动作类型**: 连续控制（`tanh` 归一化）
- **动作约束**: 推进速度 ≤ 0.4，转向角 ≤ 0.3

### 3. 感官空间复杂度

- **化学感官 (chemo)**: 128 维
- **温度感官 (thermo)**: 32 维
- **触觉感官 (touch)**: 64 维
- **总感官维度**: 224 维
- **感官编码**: 多层 MLP（4→hidden→感官维度）

### 4. 空间复杂度

- **空间维度**: 2D 平面
- **空间范围**: 10×10 单位
- **障碍物数量**: 2 个固定圆形障碍
- **场源数量**: 化学源 2 个，热源 1 个

### 5. 动态复杂度

- **状态转移**: MLP（260+32 → 512 → 256）
- **噪声模型**: 时空相关噪声（Ornstein-Uhlenbeck 过程）
  - 化学场：6 个基函数，时间相关 0.97
  - 温度场：5 个基函数，时间相关 0.95
- **能量动态**: 消耗 + 化学梯度补充

### 6. 奖励复杂度

- **奖励维度**: 1 维标量
- **奖励函数**: `chemo - 0.4*temp_penalty - 0.5*touch_penalty`
- **目标类型**: 隐式（最大化化学梯度，维持温度偏好）

### 7. 总体复杂度指标

```
状态空间: O(10^260) （连续）
动作空间: O(10^2) （实际使用）
感官空间: O(10^224)
计算复杂度: O(状态转移 MLP + 3个感官编码器)
记忆复杂度: O(噪声基函数状态 + 场源位置)
```

### 8. AONN 演化结果（线虫级）

- **Aspect 数量**: ~280 个
- **Pipeline 深度**: 6 层
- **自由能阈值**: ~0.08
- **演化步数**: 1000 步达到稳定

---

## 二、通用 AI 智能体世界模型设计

### 1. 状态空间复杂度（显著提升）

**基础状态组件**:
- **语义状态**: 1024-4096 维（语言/概念表示）
- **记忆状态**: 512-2048 维（工作记忆 + 长期记忆索引）
- **上下文状态**: 256-1024 维（对话历史、任务上下文）
- **物理状态**: 64-256 维（位置、姿态、工具状态）
- **目标状态**: 256-512 维（当前任务目标、子目标栈）
- **总状态维度**: **~2000-8000 维**

**状态空间特征**:
- 多层级：低层物理 → 中层语义 → 高层抽象
- 动态结构：记忆/目标可动态扩展
- 多模态融合：视觉、语言、音频统一表示

### 2. 动作空间复杂度（质的飞跃）

**动作类型**:
- **语言生成**: 离散 token 序列（词汇表 ~50K）
- **工具调用**: 结构化动作（API 调用、函数执行）
- **多模态输出**: 文本 + 图像 + 代码 + 交互
- **动作维度**: **~100-1000 维**（混合离散/连续）

**动作约束**:
- 语法约束（语言模型）
- 工具可用性约束
- 安全/伦理约束
- 上下文一致性约束

### 3. 感官空间复杂度（多模态扩展）

**感官模态**:
- **视觉**: 512-2048 维（图像特征、场景理解）
- **语言**: 512-2048 维（文本嵌入、语义向量）
- **音频**: 128-512 维（语音特征、音调）
- **多模态融合**: 256-1024 维（跨模态对齐表示）
- **总感官维度**: **~1500-5000 维**

**感官编码**:
- 预训练编码器（CLIP、BERT、Whisper）
- 多模态融合网络
- 注意力机制（跨模态对齐）

### 4. 空间复杂度（抽象化）

**空间类型**:
- **物理空间**: 3D 环境（如机器人）
- **信息空间**: 知识图谱、文档库
- **社交空间**: 多智能体交互网络
- **抽象空间**: 任务空间、概念空间

**空间规模**:
- 物理空间：可扩展到真实世界规模
- 信息空间：TB 级知识库
- 社交空间：N 个智能体交互

### 5. 动态复杂度（非线性、多智能体）

**状态转移模型**:
- **基础动态**: Transformer/RNN（处理序列依赖）
- **多智能体动态**: 博弈论、合作/竞争
- **工具使用动态**: 函数调用、API 响应
- **记忆更新**: 检索增强、长期记忆写入

**动态特征**:
- 非马尔可夫性（长期依赖）
- 多时间尺度（短期动作 vs 长期规划）
- 因果推理（工具使用链）

### 6. 奖励复杂度（多层次、抽象化）

**奖励类型**:
- **任务完成度**: 0-1 标量（任务是否完成）
- **知识获取**: 标量（新知识/技能获得）
- **社交反馈**: 向量（用户满意度、合作效果）
- **安全性**: 标量（避免有害输出）
- **奖励维度**: **~10-100 维**

**奖励函数**:
- 稀疏奖励（任务完成时）
- 密集奖励（中间步骤反馈）
- 多目标优化（任务 + 安全 + 效率）

### 7. 总体复杂度对比

| 维度 | 线虫世界模型 | 通用AI智能体世界模型 | 复杂度提升 |
|------|------------|-------------------|----------|
| **状态维度** | 260 | 2000-8000 | **8-30x** |
| **动作维度** | 2 (实际) | 100-1000 | **50-500x** |
| **感官维度** | 224 | 1500-5000 | **7-22x** |
| **空间类型** | 2D 物理 | 多类型抽象 | **质的飞跃** |
| **动态模型** | MLP | Transformer/RNN | **非线性提升** |
| **奖励维度** | 1 | 10-100 | **10-100x** |
| **多智能体** | 否 | 是 | **新增维度** |
| **工具使用** | 否 | 是 | **新增维度** |
| **长期记忆** | 否 | 是 | **新增维度** |

### 8. 复杂度量化指标

#### 计算复杂度
```
线虫: O(state_dim² + action_dim + obs_dim²) ≈ O(10^5)
通用AI: O(state_dim² + vocab_size + tool_space) ≈ O(10^8-10^12)
```

#### 参数复杂度
```
线虫: ~10^4-10^5 参数（MLP编码器）
通用AI: ~10^8-10^11 参数（预训练编码器 + 世界模型）
```

#### 记忆复杂度
```
线虫: O(噪声基函数 + 场源) ≈ O(10^1)
通用AI: O(长期记忆库 + 上下文窗口) ≈ O(10^6-10^9)
```

#### 预期演化压力
```
线虫: 自由能阈值 ~0.08，演化出 ~280 个 Aspect
通用AI: 预期自由能阈值 ~0.01-0.05，需要演化出 ~1000-10000 个 Aspect
```

---

## 三、LLMAspect 降低有效复杂度

### 1. LLMAspect 的作用机制

`LLMAspect`（见 `src/aonn/aspects/llm_aspect.py`）将外部 LLM 作为**语义先验因子**和**语义预测器**，而非黑盒大脑：

```python
# LLMAspect 的自由能贡献
F_llm = 0.5 * weight * ||semantic_prediction - llm_prediction||²
```

**核心功能**:
- **语义压缩**: LLM 将高维语言/知识空间压缩成语义潜变量
- **先验约束**: 提供语言/概念级的"正确性"指导
- **结构指引**: 动态建议网络拓扑演化方向

### 2. 有效复杂度降低机制

#### 2.1 语义压缩效应

**无 LLMAspect**:
- AONN 需要从原始感官信号（文本、图像）直接学习语义表示
- 需要演化大量 `LinearGenerativeAspect` 来建立 `internal → semantic` 映射
- 演化压力：需要 ~1000-5000 个感官 Aspect

**有 LLMAspect**:
- LLM 已在大规模语料上学习到世界统计规律
- `LLMAspect` 直接将 `semantic_context → semantic_prediction`
- 演化压力：只需要 ~100-500 个感官 Aspect（处理非语义模态）

**复杂度降低**: **5-10x**（感官 Aspect 数量）

#### 2.2 先验约束效应

**无 LLMAspect**:
- 自由能最小化只依赖低层感官误差
- 网络需要大量探索才能找到语义正确的结构
- 演化时间：数千到数万步

**有 LLMAspect**:
- 自由能包含语义先验项：`F_total = F_dynamics + F_observation + F_preference + F_llm`
- 语义错误的网络结构会被 LLM 先验项惩罚
- 演化时间：数百到数千步（**3-10x 加速**）

#### 2.3 结构指引效应

**无 LLMAspect**:
- 演化器随机探索网络拓扑
- 需要大量试错才能发现有效连接
- Pipeline 深度：需要 10-20 层才能处理复杂语义

**有 LLMAspect**:
- LLM 可提供"应该创建什么 Object/Aspect"的建议
- 演化器更快锁定有效拓扑
- Pipeline 深度：5-10 层即可（**2x 降低**）

### 3. 复杂度对比（有/无 LLMAspect）

| 指标 | 无 LLMAspect | 有 LLMAspect | 降低倍数 |
|------|------------|------------|---------|
| **感官 Aspect 数量** | 1000-5000 | 100-500 | **5-10x** |
| **Pipeline 深度** | 10-20 层 | 5-10 层 | **2x** |
| **演化步数** | 5000-20000 | 500-2000 | **3-10x** |
| **自由能阈值** | 0.01-0.05 | 0.02-0.08 | **更宽松** |
| **语义理解能力** | 需演化学习 | 预训练提供 | **质的提升** |

### 4. LLMAspect 的架构位置

```
AONN 网络结构（通用AI智能体）:

Object: semantic_context ──[LLMAspect]──> Object: semantic_prediction
                                              ↓
Object: vision ──[LinearGenerativeAspect]──> Object: internal
Object: language ──[LinearGenerativeAspect]──> Object: internal
Object: audio ──[LinearGenerativeAspect]──> Object: internal
                                              ↓
Object: internal ──[Pipeline]──> Object: action
```

**关键点**:
- `LLMAspect` 与 `LinearGenerativeAspect` 并行工作
- `LLMAspect` 提供语义先验，`LinearGenerativeAspect` 处理原始感官
- 两者在 `internal` Object 处融合，形成统一的世界模型

### 5. 自由能公式（含 LLMAspect）

```
F_total = F_dynamics + F_observation + F_preference + F_llm

其中：
- F_dynamics: 状态转移误差
- F_observation: 感官预测误差（vision/language/audio）
- F_preference: 目标先验项
- F_llm: 语义先验项（LLMAspect 贡献）
```

**LLMAspect 的贡献**:
```python
F_llm = 0.5 * weight * ||semantic_prediction - llm_prediction||²
```

这相当于：
```
-log p(semantic | LLM_prior) ≈ 0.5 * ||semantic - LLM_pred||²
```

### 6. 实现建议

1. **LLMAspect 配置**:
   ```python
   llm_aspect = LLMAspect(
       name="semantic_prior",
       src_names=["semantic_context"],
       dst_names=["semantic_prediction"],
       llm_client=llm_client,  # 可以是真实 LLM 或 MockLLMClient
       loss_weight=0.5,  # 语义先验权重
   )
   ```

2. **演化器集成**:
   - `LLMAspect` 在初始化时创建（不通过演化）
   - 演化器优先创建与 `semantic_prediction` 连接的 Aspect
   - Pipeline 演化时考虑语义先验约束

3. **自由能平衡**:
   - 调整 `F_llm` 的权重，避免过度依赖 LLM
   - 保持 AONN 的自主演化能力

---

## 四、总结

### 线虫世界模型 → 通用AI智能体世界模型

**复杂度提升**:
- 状态/动作/感官维度：**8-500x**
- 动态模型：从 MLP 到 Transformer/RNN
- 新增维度：多智能体、工具使用、长期记忆

**预期演化压力**:
- Aspect 数量：280 → 1000-10000
- Pipeline 深度：6 → 10-20
- 演化步数：1000 → 5000-20000

### LLMAspect 的降复杂度效应

**有效复杂度降低**:
- 感官 Aspect：**5-10x 减少**
- Pipeline 深度：**2x 减少**
- 演化步数：**3-10x 加速**

**关键机制**:
1. **语义压缩**: LLM 预训练知识 → 语义潜变量
2. **先验约束**: 语义先验项引导演化方向
3. **结构指引**: LLM 建议有效网络拓扑

**结论**: LLMAspect 不会降低世界模型的**原始复杂度**（状态/动作/感官维度仍然很大），但会显著降低 AONN 的**有效复杂度**和**演化成本**，使通用AI智能体世界模型在 AONN 框架下变得可行。

---

## 五、实现路径

### 阶段 1: 基础通用AI世界模型
- 实现多模态感官（vision/language/audio）
- 扩展状态空间到 2000+ 维
- 实现工具调用接口

### 阶段 2: 集成 LLMAspect
- 添加 `LLMAspect` 到 AONN 网络
- 配置语义先验权重
- 测试演化加速效果

### 阶段 3: 优化演化策略
- 调整演化器规则以利用 LLM 先验
- 优化 Pipeline 深度控制
- 平衡自主演化与 LLM 指导

### 阶段 4: 长期记忆与多智能体
- 实现外部记忆库
- 支持多智能体交互
- 扩展奖励函数到多目标

