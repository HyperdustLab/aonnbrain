# 纯 FEP MNIST 60000步实验结果分析

## 实验概述

- **实验类型**: 纯自由能原理（FEP）MNIST 手写数字识别
- **总步数**: 60000步（相当于1个完整epoch）
- **网络架构**: 
  - EncoderAspect（卷积编码器）：`vision -> internal`
  - ObservationAspect（卷积解码器）：`internal -> vision`
  - DynamicsAspect：`internal + action -> internal_{t+1}`（在MNIST中几乎无作用）
  - PreferenceAspect：`internal -> target`（先验约束）
  - 独立分类器：用于评估（不参与自由能计算）

## 关键结果

### 1. 自由能变化

- **初始自由能**: 715.80
- **最终自由能**: 210.47
- **降低幅度**: 70.60% ✅
- **最低自由能**: 90.74（在训练过程中达到）
- **平均自由能**: 267.27
- **标准差**: 72.82

**分析**：
- 自由能大幅降低，说明学习确实发生
- 自由能波动较大（标准差72.82），说明训练过程不稳定
- 最终自由能（210.47）高于最低值（90.74），可能存在过拟合或训练不稳定

### 2. 准确率表现

- **最终训练准确率**: 6.00% ⚠️
- **最终验证准确率**: 50.40% ✅
- **最高准确率**: 100%（训练过程中）
- **平均准确率**: 9.54%
- **标准差**: 29.37%

**分析**：
- **验证准确率（50.40%）远高于训练准确率（6.00%）**，可能原因：
  1. 训练时评估使用的是小批量（100个样本），样本量小导致统计不稳定
  2. 验证时使用的是完整验证集（10000个样本），更可靠
  3. 训练准确率计算可能有bug或使用了不同的评估方式
  
- **验证准确率50.40%**：
  - 明显高于随机猜测（10%），说明模型确实学到了某些模式
  - 但远低于理想值（>90%），说明学习效果不理想

### 3. 自由能组件分析

#### 最终值分布：
- **F_obs**: 207.02 (98.4%) - 观察生成模型
- **F_encoder**: 0.61 (0.3%) - 编码器
- **F_dyn**: 0.10 (0.0%) - 状态转移模型
- **F_pref**: 2.74 (1.3%) - 先验约束

#### 平均值分布：
- **F_obs**: 262.24 (98.1%)
- **F_encoder**: 1.29 (0.5%)
- **F_dyn**: 0.17 (0.1%)
- **F_pref**: 3.56 (1.3%)

**关键发现**：

1. **F_obs占主导（98%+）**：
   - 说明观察重建是主要挑战
   - ObservationAspect（卷积解码器）的学习难度最大
   - 这可能是因为图像重建比分类更困难

2. **F_dyn几乎为0**：
   - 证实了之前的分析：在MNIST静态分类任务中，DynamicsAspect几乎没有作用
   - 因为MNIST没有真正的状态转移，每个样本是独立的

3. **F_encoder很小（0.3-0.5%）**：
   - 编码器学习相对容易
   - 说明从图像到内部状态的映射学习得较好

4. **F_pref较小（1.3%）**：
   - 先验约束相对容易满足
   - 但可能权重设置不够，无法有效引导分类

### 4. 学习趋势

- **前1000步平均自由能**: 304.92
- **后1000步平均自由能**: 268.97
- **改善幅度**: 11.79%

**分析**：
- 学习趋势存在，但改善幅度不大
- 说明模型可能已经接近当前架构的学习极限
- 或者需要更长时间的训练才能进一步改善

## 问题诊断

### 1. 观察重建占主导（F_obs = 98%）

**问题**：
- ObservationAspect（解码器）的学习难度过大
- 图像重建任务比分类任务更困难
- 自由能主要来自观察重建误差，而不是分类误差

**可能原因**：
- 卷积解码器架构可能不够强大
- 学习率可能不适合观察重建任务
- 观察重建和分类任务之间存在冲突

**改进建议**：
1. **调整自由能权重**：降低F_obs的权重，提高F_pref的权重
2. **改进解码器架构**：使用更强大的卷积解码器（如VAE风格）
3. **分离学习目标**：使用不同的学习率分别优化观察重建和分类
4. **简化观察重建**：使用更简单的解码器，或者降低观察重建的精度要求

### 2. 验证准确率不理想（50.40%）

**问题**：
- 虽然高于随机猜测，但远低于理想值
- 说明模型没有很好地学习分类任务

**可能原因**：
1. **自由能不平衡**：F_obs占主导，分类任务（F_pref）被忽略
2. **先验约束不足**：F_pref权重太小（1.3%），无法有效引导分类
3. **内部状态表示不足**：128维可能不足以编码10个类别的信息
4. **学习率设置**：可能不适合当前任务

**改进建议**：
1. **增加F_pref权重**：将分类先验的权重提高10-100倍
2. **增加内部状态维度**：从128增加到256或512
3. **调整学习率**：针对不同组件使用不同的学习率
4. **改进PreferenceAspect**：使用更强的目标状态映射

### 3. 训练不稳定（自由能波动大）

**问题**：
- 自由能标准差72.82，波动较大
- 准确率标准差29.37%，波动很大

**可能原因**：
- 学习率可能过高
- 梯度裁剪可能不够
- 批量大小可能太小

**改进建议**：
1. **降低学习率**：从0.001降低到0.0001或0.0005
2. **增加批量大小**：如果可能，增加批量大小
3. **改进梯度裁剪**：使用更严格的梯度裁剪
4. **使用学习率调度**：使用学习率衰减策略

### 4. DynamicsAspect无作用

**问题**：
- F_dyn几乎为0，在MNIST静态分类任务中无意义

**改进建议**：
- **移除DynamicsAspect**：在静态分类任务中不需要状态转移模型
- **简化架构**：只保留Encoder、Observation和Preference三个Aspect

## 改进方案

### 方案1：调整自由能权重（快速尝试）

```python
# 在 run_pure_fep_mnist.py 中调整
config = {
    "obs_weight": 0.1,      # 降低F_obs权重（从1.0降到0.1）
    "pref_weight": 10.0,    # 提高F_pref权重（从1.0提高到10.0）
    "encoder_weight": 1.0,  # 保持F_encoder权重
}
```

### 方案2：移除DynamicsAspect（简化架构）

```python
# 移除DynamicsAspect，只保留：
# - EncoderAspect
# - ObservationAspect  
# - PreferenceAspect
```

### 方案3：改进PreferenceAspect（增强分类先验）

```python
# 使用更强的目标状态映射
# 例如：使用可学习的类别嵌入，而不是简单的线性投影
```

### 方案4：使用分离优化器（不同学习率）

```python
# 为不同组件使用不同的优化器和学习率
encoder_optimizer = Adam(encoder.parameters(), lr=0.001)
observation_optimizer = Adam(observation.parameters(), lr=0.0001)  # 更低的学习率
preference_optimizer = Adam(preference.parameters(), lr=0.01)  # 更高的学习率
```

## 结论

1. **学习确实发生**：自由能降低了70.60%，验证准确率达到50.40%
2. **主要问题**：观察重建占主导（98%），分类任务被忽略
3. **关键改进方向**：
   - 调整自由能权重，提高分类先验的重要性
   - 移除无用的DynamicsAspect
   - 改进PreferenceAspect，增强分类引导
   - 使用分离优化器，针对不同组件使用不同学习率

## 下一步

1. **快速验证**：尝试方案1（调整权重），看是否能快速提升验证准确率
2. **架构简化**：尝试方案2（移除DynamicsAspect），简化系统
3. **深度优化**：如果快速方案有效，再尝试方案3和方案4

